2025-12-09 21:46:32,996 - lib.harness - INFO - Server started on port 50051
2025-12-09 21:47:02,700 - __main__ - INFO - AgentMain received SendMessage request request {
  message_id: "1"
  role: ROLE_USER
  parts {
    text: "what is 3+4"
  }
  metadata {
    fields {
      key: "user_id"
      value {
        string_value: "40"
      }
    }
    fields {
      key: "session_id"
      value {
        string_value: "5271"
      }
    }
    fields {
      key: "agent_name"
      value {
        string_value: "dice"
      }
    }
  }
}

2025-12-09 21:47:02,701 - __main__ - INFO - Mapped content: parts=[Part(
  text='what is 3+4'
)] role='user' <<
2025-12-09 21:47:02,701 - __main__ - INFO - Metadata: {'session_id': '5271', 'user_id': '40', 'agent_name': 'dice'}
2025-12-09 21:47:06,792 - grpc._server - ERROR - Exception calling application: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.
Traceback (most recent call last):
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\connection.py", line 855, in connect_check_health
    sock = self.retry.call_with_retry(
        lambda: self._connect(), lambda error: self.disconnect(error)
    )
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\retry.py", line 116, in call_with_retry
    return do()
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\connection.py", line 856, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
            ~~~~~~~~~~~~~^^
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\connection.py", line 1306, in _connect
    raise err
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\connection.py", line 1290, in _connect
    sock.connect(socket_address)
    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\grpc\_server.py", line 608, in _call_behavior
    response_or_iterator = behavior(argument, context)
  File "c:\py_code\multi_agent\app\main.py", line 47, in SendMessage
    memory.set_user_memory(user_id, session_id, content.parts[0].text)
    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\py_code\multi_agent\lib\memory.py", line 19, in set_user_memory
    save_to_memory(client_id, session_id, "user: "+ memory+"\n")
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\py_code\multi_agent\lib\memory.py", line 38, in save_to_memory
    mem = r.get(key)
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\commands\core.py", line 1923, in get
    return self.execute_command("GET", name, keys=[name])
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\client.py", line 657, in execute_command
    return self._execute_command(*args, **options)
           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\client.py", line 663, in _execute_command
    conn = self.connection or pool.get_connection()
                              ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\utils.py", line 196, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\connection.py", line 2603, in get_connection
    connection.connect()
    ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\connection.py", line 846, in connect
    self.connect_check_health(check_health=True)
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\azaha\AppData\Local\Programs\Python\Python313\Lib\site-packages\redis\connection.py", line 863, in connect_check_health
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.
2025-12-09 21:49:57,543 - __main__ - INFO - AgentMain received SendMessage request request {
  message_id: "1"
  role: ROLE_USER
  parts {
    text: "what is 534+432"
  }
  metadata {
    fields {
      key: "user_id"
      value {
        string_value: "83"
      }
    }
    fields {
      key: "session_id"
      value {
        string_value: "6487"
      }
    }
    fields {
      key: "agent_name"
      value {
        string_value: "dice"
      }
    }
  }
}

2025-12-09 21:49:57,543 - __main__ - INFO - Mapped content: parts=[Part(
  text='what is 534+432'
)] role='user' <<
2025-12-09 21:49:57,543 - __main__ - INFO - Metadata: {'session_id': '6487', 'user_id': '83', 'agent_name': 'dice'}
2025-12-09 21:49:57,552 - lib.harness - INFO - Incoming: parts=[Part(
  text='what is 534+432'
)] role='user'
2025-12-09 21:50:25,852 - app.dice_roller - INFO - Dice LLM Response: Sure, let's roll the dice to see what number comes up. Here we go: 3

Now, let's add the numbers together: 534 + 432 = 966. So, the result of the dice roll is 3, and the sum of 534 and 432 is 966.
2025-12-09 21:50:25,854 - lib.harness - INFO - Received response: {'request': 'what is 534+432', 'memory_snapshot': 'user: what is 534+432\n', 'response': "Sure, let's roll the dice to see what number comes up. Here we go: 3\n\nNow, let's add the numbers together: 534 + 432 = 966. So, the result of the dice roll is 3, and the sum of 534 and 432 is 966."}
2025-12-09 21:50:52,053 - __main__ - INFO - AgentMain received SendMessage request request {
  message_id: "2"
  role: ROLE_USER
  parts {
    text: "what did I ask about"
  }
  metadata {
    fields {
      key: "user_id"
      value {
        string_value: "83"
      }
    }
    fields {
      key: "session_id"
      value {
        string_value: "6487"
      }
    }
    fields {
      key: "agent_name"
      value {
        string_value: "lg_greeter"
      }
    }
  }
}

2025-12-09 21:50:52,053 - __main__ - INFO - Mapped content: parts=[Part(
  text='what did I ask about'
)] role='user' <<
2025-12-09 21:50:52,053 - __main__ - INFO - Metadata: {'session_id': '6487', 'user_id': '83', 'agent_name': 'lg_greeter'}
2025-12-09 21:50:52,068 - lib.harness - INFO - Incoming: parts=[Part(
  text='what did I ask about'
)] role='user'
2025-12-09 21:50:59,708 - app.lg_greeter - INFO - LG LLM Response: You asked about the sum of 534 and 432.
2025-12-09 21:50:59,711 - lib.harness - INFO - Received response: {'request': 'what did I ask about', 'memory_snapshot': "user: what is 534+432\n\nagent: Sure, let's roll the dice to see what number comes up. Here we go: 3\n\nNow, let's add the numbers together: 534 + 432 = 966. So, the result of the dice roll is 3, and the sum of 534 and 432 is 966.\n\nuser: what did I ask about\n", 'response': 'You asked about the sum of 534 and 432.'}
2025-12-09 21:51:36,788 - __main__ - INFO - AgentMain received SendMessage request request {
  message_id: "1"
  role: ROLE_USER
  parts {
    text: "what is 343-234"
  }
  metadata {
    fields {
      key: "user_id"
      value {
        string_value: "5"
      }
    }
    fields {
      key: "session_id"
      value {
        string_value: "7974"
      }
    }
    fields {
      key: "agent_name"
      value {
        string_value: "dice"
      }
    }
  }
}

2025-12-09 21:51:36,788 - __main__ - INFO - Mapped content: parts=[Part(
  text='what is 343-234'
)] role='user' <<
2025-12-09 21:51:36,788 - __main__ - INFO - Metadata: {'session_id': '7974', 'user_id': '5', 'agent_name': 'dice'}
2025-12-09 21:51:36,791 - lib.harness - INFO - Incoming: parts=[Part(
  text='what is 343-234'
)] role='user'
2025-12-09 21:51:49,929 - app.dice_roller - INFO - Dice LLM Response: The result of 343 minus 234 is 109. Now, let's roll a die. You got a 4!
2025-12-09 21:51:49,930 - lib.harness - INFO - Received response: {'request': 'what is 343-234', 'memory_snapshot': 'user: what is 343-234\n', 'response': "The result of 343 minus 234 is 109. Now, let's roll a die. You got a 4!"}
2025-12-09 21:51:57,360 - __main__ - INFO - AgentMain received SendMessage request request {
  message_id: "2"
  role: ROLE_USER
  parts {
    text: "what did I ask "
  }
  metadata {
    fields {
      key: "user_id"
      value {
        string_value: "5"
      }
    }
    fields {
      key: "session_id"
      value {
        string_value: "7974"
      }
    }
    fields {
      key: "agent_name"
      value {
        string_value: "lg_greeter"
      }
    }
  }
}

2025-12-09 21:51:57,361 - __main__ - INFO - Mapped content: parts=[Part(
  text='what did I ask '
)] role='user' <<
2025-12-09 21:51:57,361 - __main__ - INFO - Metadata: {'session_id': '7974', 'user_id': '5', 'agent_name': 'lg_greeter'}
2025-12-09 21:51:57,365 - lib.harness - INFO - Incoming: parts=[Part(
  text='what did I ask '
)] role='user'
2025-12-09 21:52:04,342 - app.lg_greeter - INFO - LG LLM Response: You asked "what is 343-234."
2025-12-09 21:52:04,342 - lib.harness - INFO - Received response: {'request': 'what did I ask ', 'memory_snapshot': "user: what is 343-234\n\nagent: The result of 343 minus 234 is 109. Now, let's roll a die. You got a 4!\n\nuser: what did I ask \n", 'response': 'You asked "what is 343-234."'}
2025-12-09 21:52:25,864 - __main__ - INFO - AgentMain received SendMessage request request {
  message_id: "3"
  role: ROLE_USER
  parts {
    text: "what was the response of the agent to my question"
  }
  metadata {
    fields {
      key: "user_id"
      value {
        string_value: "5"
      }
    }
    fields {
      key: "session_id"
      value {
        string_value: "7974"
      }
    }
    fields {
      key: "agent_name"
      value {
        string_value: "adk_greeter"
      }
    }
  }
}

2025-12-09 21:52:25,865 - __main__ - INFO - Mapped content: parts=[Part(
  text='what was the response of the agent to my question'
)] role='user' <<
2025-12-09 21:52:25,865 - __main__ - INFO - Metadata: {'session_id': '7974', 'user_id': '5', 'agent_name': 'adk_greeter'}
2025-12-09 21:52:25,867 - lib.harness - INFO - Creating session with state: {'memory_snapshot': 'user: what is 343-234\n\nagent: The result of 343 minus 234 is 109. Now, let\'s roll a die. You got a 4!\n\nuser: what did I ask \n\nagent: You asked "what is 343-234."\n\nuser: what was the response of the agent to my question\n'}
2025-12-09 21:52:26,613 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-09 21:52:26,614 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-12-09 21:52:27,957 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.
2025-12-09 21:52:27,957 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-09 21:52:27,958 - lib.harness - INFO - Received response: content=Content(
  parts=[
    Part(
      text='You asked "what did I ask" and the agent responded with "You asked "what is 343-234.""',
      thought_signature=b'\n\xd5\x03\x01r\xc8\xda|\xe5q\n~\xccR\x1a\xb3\xa5\xd6\x81 J\x01\xe4\xc1\x86\xa5\xfcD\xc8\xed\xbe\x81\x1dGp\xe4\xbe\xb2(#(\xd4\x1a\xc0\xaa"\xf8A\x8d\xbf\xf6I\x16\x9ao\n{o\x07n\xdc?\xa0\x8c.\x1cm(\t,\xa2r\xbd\xe6\xa1\xf3\xac\xd1\x1b\x8d(0\xfd\xb1,\xb6F\x08\x91\xdf\xcb\x88}x\xa3;U...'
    ),
  ],
  role='model'
) grounding_metadata=None partial=None turn_complete=None finish_reason=<FinishReason.STOP: 'STOP'> error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=GenerateContentResponseUsageMetadata(
  candidates_token_count=28,
  prompt_token_count=231,
  prompt_tokens_details=[
    ModalityTokenCount(
      modality=<MediaModality.TEXT: 'TEXT'>,
      token_count=231
    ),
  ],
  thoughts_token_count=124,
  total_token_count=383
) live_session_resumption_update=None input_transcription=None output_transcription=None invocation_id='e-7165ecaa-7b17-4e64-98b7-c163815c51de' author='Lead_Agent' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='729739e4-98ca-4527-9ba2-ab92ef23d8b8' timestamp=1765317145.869738
2025-12-09 21:52:50,338 - __main__ - INFO - AgentMain received SendMessage request request {
  message_id: "4"
  role: ROLE_USER
  parts {
    text: "and what about the question before that - what was the answer "
  }
  metadata {
    fields {
      key: "user_id"
      value {
        string_value: "5"
      }
    }
    fields {
      key: "session_id"
      value {
        string_value: "7974"
      }
    }
    fields {
      key: "agent_name"
      value {
        string_value: "adk_greeter"
      }
    }
  }
}

2025-12-09 21:52:50,339 - __main__ - INFO - Mapped content: parts=[Part(
  text='and what about the question before that - what was the answer '
)] role='user' <<
2025-12-09 21:52:50,339 - __main__ - INFO - Metadata: {'session_id': '7974', 'user_id': '5', 'agent_name': 'adk_greeter'}
2025-12-09 21:52:50,358 - lib.harness - INFO - Creating session with state: {'memory_snapshot': 'user: what is 343-234\n\nagent: The result of 343 minus 234 is 109. Now, let\'s roll a die. You got a 4!\n\nuser: what did I ask \n\nagent: You asked "what is 343-234."\n\nuser: what was the response of the agent to my question\n\nagent: You asked "what did I ask" and the agent responded with "You asked "what is 343-234.""\n\nuser: and what about the question before that - what was the answer \n'}
2025-12-09 21:52:51,307 - google_adk.google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-12-09 21:52:51,307 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-12-09 21:52:52,553 - google_adk.google.adk.models.google_llm - INFO - Response received from the model.
2025-12-09 21:52:52,553 - google_genai.types - WARNING - Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.
2025-12-09 21:52:52,554 - lib.harness - INFO - Received response: content=Content(
  parts=[
    Part(
      text='The answer to your question "what is 343-234" was "The result of 343 minus 234 is 109. Now, let\'s roll a die. You got a 4!".',
      thought_signature=b'\n\xb7\x04\x01r\xc8\xda|LQc\xe4\xa5\xebm\x9e\xa0.o\x86\xa3s\xf4o=Un\xc4\xc1\xacU\xe9\x86\xa9\x8a Oo\t\xb1\xcb\x05V\xb4z%\xce#\xa2\x8f\xbcp\xbd\xae\xf8#@WBa\r\xa6\xd3\x8fb\xd2\xf1\xfd\xd7d\xf43\x14\xc3\x8b\xaf\xe3O\x89\x9e\xf5J.Nj\x89&\x9f\xd3\xa1@/[\xb7\xa4\xcd\xf8...'
    ),
  ],
  role='model'
) grounding_metadata=None partial=None turn_complete=None finish_reason=<FinishReason.STOP: 'STOP'> error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=GenerateContentResponseUsageMetadata(
  candidates_token_count=52,
  prompt_token_count=281,
  prompt_tokens_details=[
    ModalityTokenCount(
      modality=<MediaModality.TEXT: 'TEXT'>,
      token_count=281
    ),
  ],
  thoughts_token_count=170,
  total_token_count=503
) live_session_resumption_update=None input_transcription=None output_transcription=None invocation_id='e-73180ac5-f893-40c2-ac57-0e962ef181a8' author='Lead_Agent' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='2f91b949-0cb2-4066-bf97-3045bbce32b4' timestamp=1765317170.360142
